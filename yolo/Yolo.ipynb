{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOQqeu6RaSI1/m/JF6NjOnd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AfsDj3nNSd6g","executionInfo":{"status":"ok","timestamp":1720114050832,"user_tz":-330,"elapsed":104283,"user":{"displayName":"Priya Dharshini MV","userId":"14285307281602584851"}},"outputId":"4d9eb8b4-ba6d-44d4-8553-8689e9ecca75"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q ultralytics\n","!pip install -q IPython"]},{"cell_type":"code","source":["import ultralytics\n","from IPython import display"],"metadata":{"id":"CeiiH0SaTWV_","executionInfo":{"status":"ok","timestamp":1720114083770,"user_tz":-330,"elapsed":6249,"user":{"displayName":"Priya Dharshini MV","userId":"14285307281602584851"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["ultralytics.checks()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wscbpi00TWZZ","executionInfo":{"status":"ok","timestamp":1720114090182,"user_tz":-330,"elapsed":1981,"user":{"displayName":"Priya Dharshini MV","userId":"14285307281602584851"}},"outputId":"d80800c3-76c8-445a-b592-916659351eaa"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.49 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 30.2/107.7 GB disk)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n"],"metadata":{"id":"vfsUHblcTqMD","executionInfo":{"status":"ok","timestamp":1720114385415,"user_tz":-330,"elapsed":483,"user":{"displayName":"Priya Dharshini MV","userId":"14285307281602584851"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yY5DgQpvTqP0","executionInfo":{"status":"ok","timestamp":1720114436925,"user_tz":-330,"elapsed":48709,"user":{"displayName":"Priya Dharshini MV","userId":"14285307281602584851"}},"outputId":"9eadb544-2415-4003-a21f-047c4850d70e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/yolo_final/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uB6o5PVxTqS9","executionInfo":{"status":"ok","timestamp":1720114579259,"user_tz":-330,"elapsed":724,"user":{"displayName":"Priya Dharshini MV","userId":"14285307281602584851"}},"outputId":"50f41623-0f66-414c-e2ee-6165faa7e299"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/yolo_final\n"]}]},{"cell_type":"code","source":["!yolo task=detect mode=train model=yolov8s.pt data=coco8.yaml epochs=10 plots=True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XdR53Ui2TqVd","executionInfo":{"status":"ok","timestamp":1720116065513,"user_tz":-330,"elapsed":224052,"user":{"displayName":"Priya Dharshini MV","userId":"14285307281602584851"}},"outputId":"e3c583d9-a9c9-4e6c-9b49-53098350da2a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.49 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=coco8.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train6\n","\n","Dataset 'coco8.yaml' images not found ⚠️, missing path '/content/datasets/coco8/images/val'\n","Downloading https://ultralytics.com/assets/coco8.zip to '/content/datasets/coco8.zip'...\n","100% 433k/433k [00:00<00:00, 10.0MB/s]\n","Unzipping /content/datasets/coco8.zip to /content/datasets/coco8...: 100% 25/25 [00:00<00:00, 3899.07file/s]\n","Dataset download success ✅ (0.8s), saved to \u001b[1m/content/datasets\u001b[0m\n","\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 13.9MB/s]\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n","Model summary: 225 layers, 11166560 parameters, 11166544 gradients, 28.8 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train6', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<00:00, 113.40it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco8/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<00:00, 1280.12it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8/labels/val.cache\n","Plotting labels to runs/detect/train6/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/detect/train6\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10         0G      1.204      2.854      1.426         13        640: 100% 1/1 [00:13<00:00, 13.43s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.74s/it]\n","                   all          4         17      0.788      0.826      0.917      0.707\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10         0G     0.7912      1.952      1.214         13        640: 100% 1/1 [00:11<00:00, 11.86s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.66s/it]\n","                   all          4         17       0.79      0.823      0.916      0.706\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10         0G      0.808      1.444      1.129         13        640: 100% 1/1 [00:10<00:00, 10.12s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.13s/it]\n","                   all          4         17      0.822      0.897      0.944      0.709\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10         0G     0.9033      1.416      1.304         13        640: 100% 1/1 [00:10<00:00, 10.92s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.03s/it]\n","                   all          4         17      0.821      0.896      0.944       0.71\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10         0G      1.197      3.473      1.462         13        640: 100% 1/1 [00:10<00:00, 10.90s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.05s/it]\n","                   all          4         17      0.823      0.886      0.941      0.701\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10         0G     0.9479      2.371      1.111         13        640: 100% 1/1 [00:11<00:00, 11.06s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.99s/it]\n","                   all          4         17      0.826      0.886      0.942      0.707\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10         0G      1.124      2.694      1.425         13        640: 100% 1/1 [00:11<00:00, 11.41s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  3.00s/it]\n","                   all          4         17      0.819      0.882       0.94      0.714\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10         0G     0.8581       1.79      1.165         13        640: 100% 1/1 [00:11<00:00, 11.34s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.28s/it]\n","                   all          4         17      0.825      0.871      0.939      0.693\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10         0G     0.7974      2.668      1.212         13        640: 100% 1/1 [00:12<00:00, 12.62s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.40s/it]\n","                   all          4         17      0.821      0.868      0.936      0.689\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10         0G      1.136      2.781      1.365         13        640: 100% 1/1 [00:12<00:00, 12.71s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.21s/it]\n","                   all          4         17      0.807      0.866      0.935      0.677\n","\n","10 epochs completed in 0.048 hours.\n","Optimizer stripped from runs/detect/train6/weights/last.pt, 22.6MB\n","Optimizer stripped from runs/detect/train6/weights/best.pt, 22.6MB\n","\n","Validating runs/detect/train6/weights/best.pt...\n","Ultralytics YOLOv8.2.49 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n","Model summary (fused): 168 layers, 11156544 parameters, 0 gradients, 28.6 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:05<00:00,  5.20s/it]\n","                   all          4         17       0.82      0.882       0.94      0.714\n","                person          3         10      0.844        0.6      0.663      0.345\n","                   dog          1          1       0.86          1      0.995      0.895\n","                 horse          1          2      0.801          1      0.995      0.801\n","              elephant          1          2          1      0.691      0.995      0.451\n","              umbrella          1          1      0.686          1      0.995      0.895\n","          potted plant          1          1      0.729          1      0.995      0.895\n","Speed: 2.4ms preprocess, 1283.0ms inference, 0.0ms loss, 2.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train6\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"code","source":["!yolo task=detect mode=val model=/content/drive/MyDrive/yolo_final/runs/detect/train6/weights/best.pt data=coco8.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W72Z2gtmTqYk","executionInfo":{"status":"ok","timestamp":1720116214084,"user_tz":-330,"elapsed":20682,"user":{"displayName":"Priya Dharshini MV","userId":"14285307281602584851"}},"outputId":"0e53267b-90eb-4a30-86b3-9add34a74361"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.49 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n","Model summary (fused): 168 layers, 11156544 parameters, 0 gradients, 28.6 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.21s/it]\n","                   all          4         17       0.82      0.882       0.94      0.714\n","                person          3         10      0.844        0.6      0.663      0.345\n","                   dog          1          1       0.86          1      0.995      0.895\n","                 horse          1          2      0.801          1      0.995      0.801\n","              elephant          1          2          1      0.691      0.995      0.451\n","              umbrella          1          1      0.686          1      0.995      0.895\n","          potted plant          1          1      0.729          1      0.995      0.895\n","Speed: 24.4ms preprocess, 760.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val2\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/val\n"]}]},{"cell_type":"code","source":["!yolo task=detect mode=predict model=yolov8s source=/content/datasets/coco8/images/val conf=0.30"],"metadata":{"id":"_t36CYnsTqbj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720116233310,"user_tz":-330,"elapsed":10662,"user":{"displayName":"Priya Dharshini MV","userId":"14285307281602584851"}},"outputId":"4f86432f-d777-4523-bea9-854e14ab7c86"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.49 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n","YOLOv8s summary (fused): 168 layers, 11156544 parameters, 0 gradients, 28.6 GFLOPs\n","\n","image 1/4 /content/datasets/coco8/images/val/000000000036.jpg: 640x512 1 person, 1 umbrella, 585.7ms\n","image 2/4 /content/datasets/coco8/images/val/000000000042.jpg: 480x640 1 dog, 1 teddy bear, 483.3ms\n","image 3/4 /content/datasets/coco8/images/val/000000000049.jpg: 640x512 5 persons, 2 horses, 1 potted plant, 527.0ms\n","image 4/4 /content/datasets/coco8/images/val/000000000061.jpg: 512x640 1 person, 2 elephants, 525.6ms\n","Speed: 2.4ms preprocess, 530.4ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}]}]}